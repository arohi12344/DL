TITLE: RECURRENT NEURAL NETWORK (RNN)

Problem Statement :
Use the Google stock prices dataset and design a time series analysis and
prediction system using RNN..
Objective :
To understand and implement:
1. RNN
2. Analyze historical stock price data and predict future prices based on the learned
patterns and trends in the data using Time series analysis and RNN based model.
Theory:
What is RNN?
RNN or Recurrent Neural Network is a type of neural network architecture that is
specifically designed to process data that has sequential dependencies and
temporal patterns., such as time series data or natural language data. Unlike
traditional feedforward neural networks, the key component of an RNN is the
recurrent connection, which allows information to flow from one time step to the
next. This enables the network to capture long-term dependencies in the data.
RNNs also have a hidden state or memory that can store information about the
past inputs and use it to influence future predictions.
RNNs are widely used in various applications, including natural language
processing (NLP), speech recognition, machine translation, and time series
analysis. In the context of time series analysis, RNNs can be used to model and
forecast future values based on historical data patterns.
Recurrent Neural Network Architecture :
The architecture of a Recurrent Neural Network (RNN) consists of three main
components: the input layer, the recurrent layer, and the output layer

1. Input Layer:
The input layer or the first layer receives sequential data as input. In the case of
time series analysis, each time step&#39;s input could include features such as historical
stock prices, trading volumes, or other relevant factors. The input layer passes the
input data to the recurrent layer.
2. Recurrent Layer:
The recurrent layer is the core component of the RNN architecture. It contains
recurrent units, often referred to as memory cells or hidden units. Each recurrent
unit processes a time step&#39;s input and its own hidden state from the previous time
step. The hidden state serves as the memory of the network, capturing and storing
information from previous time steps. The recurrent layer applies weights to the
input and the previous hidden state, performs calculations, and generates an
updated hidden state. The updated hidden state is passed to the next time step,
allowing the network to retain information across multiple time steps.
Formula for calculating the current state

where:
h t =&gt; current state
h t-1 =&gt; previous state
x t =&gt; input state
The recurrent layer can have multiple recurrent units, and the choice of the specific
recurrent unit type, such as the vanilla RNN, LSTM (Long Short-Term Memory), or
GRU (Gated Recurrent Unit), depends on the specific requirements of the task.

3. Output Layer:
The output layer receives the final hidden state from the recurrent layer and
generates the network&#39;s prediction or output. In time series analysis, the output
layer might produce a single value prediction for the next time step or multiple
predictions for future time steps.
The output can be calculated as:

where:
y t =&gt; output
W hy =&gt; weight at output layer
The output layer can apply additional transformations, such as activation functions,
to produce the desired output format. In the Keras Documentation, it is specified
that the default activation function for LSTM based RNN is tanh and the default
recurrent activation function is sigmoid. Therefore the formula for those default
activation functions are:
a. Tanh

b. Sigmoid

Steps to create an RNN Model for our use case:
Step 1: Import the necessary libraries
We will be using TensorFlow Keras for building our RNN models. Apart from the model
architecture, we will be needing numpy, pandas, sklearn for data preparation and
matplotlib, seaborn for data visualization.

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
import datetime
import seaborn as sns
from sklearn.preprocessing import MinMaxScaler
from sklearn.decomposition import PCA
from sklearn.model_selection import train_test_split
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import LSTM
from sklearn.metrics import r2_score
Step 2 : Loading the Dataset
Install the Google stock prices dataset from kaggle and load it using pandas
data=pd.read_csv(&quot;/content/Google_Stock_Price_Train.csv&quot;)
Step 3 : Data Preprocessing
In the dataset, the Volume column had thousand separated values, which is taken as string
when usually loading to Pandas DataFrame. Convert such columns into numeric data
data[&#39;Volume&#39;]=data[&#39;Volume&#39;].str.replace(&#39;,&#39;,&#39;&#39;).astype(float)
We don&#39;t encounter null values in this dataset and we do not need to handle outliers.
Step 4 : Feature Selection
We have to normalize or scale the features to ensure the data are within a similar range.
This step is crucial for effective training of the RNN model. Drawing the Correlation Matrix
and finding the Correlation Coefficient checking are a few mechanisms to check the
relationship between the different features with the predicting attribute.
We can draw the correlation matrix using seaborn as follows:
plt.figure(figsize=(6,6))
sns.heatmap(data.corr())
Step 5 : Sequence Generation:

To develop an RNN model, we have to convert the dataset into sequences of inputs and
corresponding output targets. To do that, first we have to find a pattern in the data available
and define the number of timesteps according to the pattern. In our particular case, since
we are dealing with time series data, we have to specify how many past data points we will
be considering when generating the sequence. Create input sequences by sliding a window
of the defined sequence length through the dataset. Associate each input sequence with its
corresponding output target (e.g., futures’s stock price)
Step 6 : Splitting the data and Creating the model
Split the dataset into training and testing sets. The training set will be used to train the RNN
model, while the testing set will be used for evaluating its performance.
X_train, X_test, y_train, y_test =
train_test_split(X,y,test_size=0.2,random_state=50)
We will be choosing RNN’s variant, LSTM for our use case. The model’s architecture will
consist of layers including Tensorflow Keras LSTM and Dense layers with default activation
function for LSTM being tanh and default recurrent activation function being sigmoid.
model = Sequential()
model.add(LSTM(612, input_shape=(n_steps,2)))
model.add(Dense(50, activation=&#39;relu&#39;))
model.add(Dense(50, activation=&#39;relu&#39;))
model.add(Dense(30, activation=&#39;relu&#39;))
model.add(Dense(1))
After adding the layers to the model, we can compile it using the compile() method, which
sets the optimizer, loss function, and evaluation metrics for the model. Finally, we can train
the model on the training data using the fit() method and evaluate its performance on the
test data using the evaluate() method.
Step 6 : Evaluating the model
We evaluate the trained model using the testing dataset. Here we have to calculate
relevant metrics such as mean squared error (MSE), mean absolute error (MAE), to assess
the model&#39;s predictive accuracy in predictions.
mse, mae = model.evaluate(X_test, y_test, verbose=0)
Step 7 : Prediction

We utilize the trained RNN model to make predictions on unseen data or future time steps
by providing the necessary input features for the model, such as previous stock prices and
other relevant factors. We can evaluate the predictions and compare them with actual
values to assess the model&#39;s performance in a real-world scenario using mode.predict().

Conclusion:

We were able to understand and implement RNN models for time series analysis and
forecasting tasks. The developed model provided insights into the Google stock market and
its potential future directions. It showcased the capability to leverage deep learning
techniques, specifically RNNs, to make accurate predictions and informed decisions in the
financial domain.

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import Dropout

dataset_train = pd.read_csv('Google_Stock_Price_Train.csv')

dataset_train.head()

#keras only takes numpy array
training_set = dataset_train.iloc[:, 1: 2].values

training_set.shape

plt.figure(figsize=(18, 8))
plt.plot(dataset_train['Open'])
plt.title("Google Stock Open Prices")
plt.xlabel("Time (oldest -> latest)")
plt.ylabel("Stock Open Price")
plt.show()

Feature scaling
import os
if os.path.exists('config.py'):
    print(1)
else:
    print(0)

sc = MinMaxScaler(feature_range = (0, 1))
#fit: get min/max of train data
training_set_scaled = sc.fit_transform(training_set)

3.2 Data structure creation
taking the reference of past 60 days of data to predict the future stock price.
It is observed that taking 60 days of past data gives us best results.
In this data set 60 days of data means 3 months of data.
Every month as 20 days of Stock price.
X train will have data of 60 days prior to our date and y train will have data of one day after our date

## 60 timesteps and 1 output
X_train = []
y_train = []
for i in range(60, len(training_set_scaled)):
    X_train.append(training_set_scaled[i-60: i, 0])
    y_train.append(training_set_scaled[i, 0])

X_train, y_train = np.array(X_train), np.array(y_train)

X_train.shape

y_train.shape

3.3 Data reshaping
X_train = np.reshape(X_train, newshape = 
                     (X_train.shape[0], X_train.shape[1], 1))

Number of stock prices - 1449
Number of time steps - 60
Number of Indicator - 1

X_train.shape

4.Create & Fit Model
4.1 Create model

regressor = Sequential()
#add 1st lstm layer
regressor.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[1], 1)))
regressor.add(Dropout(rate = 0.2))
##add 2nd lstm layer: 50 neurons
regressor.add(LSTM(units = 50, return_sequences = True))
regressor.add(Dropout(rate = 0.2))
##add 3rd lstm layer
regressor.add(LSTM(units = 50, return_sequences = True))
regressor.add(Dropout(rate = 0.2))
##add 4th lstm layer
regressor.add(LSTM(units = 50, return_sequences = False))
regressor.add(Dropout(rate = 0.2))
##add output layer
regressor.add(Dense(units = 1))

regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')

4.2 Model fit

regressor.fit(x = X_train, y = y_train, batch_size = 32, epochs = 100)

4.3 Model evaluation
4.3.1 Read and convert

dataset_test = pd.read_csv('Google_Stock_Price_Test.csv')

dataset_test.head()

#keras only takes numpy array
real_stock_price = dataset_test.iloc[:, 1: 2].values
real_stock_price.shape

real_stock_price

4.3.2 Concat and convert
#vertical concat use 0, horizontal uses 1
dataset_total = pd.concat((dataset_train['Open'], dataset_test['Open']), 
                          axis = 0)
##use .values to make numpy array
inputs = dataset_total[len(dataset_total) - len(dataset_test) - 60:].values

4.3.3 Reshape and scale
#reshape data to only have 1 col
inputs = inputs.reshape(-1, 1)

#scale input
inputs = sc.transform(inputs)

len(inputs)

4.3.4 Create test data strucutre

X_test = []
for i in range(60, len(inputs)):
    X_test.append(inputs[i-60:i, 0])
X_test = np.array(X_test)
#add dimension of indicator
X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))

X_test.shape

4.3.5 Model prediction
predicted_stock_price = regressor.predict(X_test)

#inverse the scaled value
predicted_stock_price = sc.inverse_transform(predicted_stock_price)

4.3.6 Result visualization
##visualize the prediction and real price
plt.plot(real_stock_price, color = 'red', label = 'Real price')
plt.plot(predicted_stock_price, color = 'blue', label = 'Predicted price')

plt.title('Google price prediction')
plt.xlabel('Time')
plt.ylabel('Price')
plt.legend()
plt.show()
